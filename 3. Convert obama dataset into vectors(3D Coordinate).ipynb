{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sharing-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "promotional-webmaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wen\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pyquaternion as pyq\n",
    "from math import sin, cos\n",
    "\n",
    "sys.path.insert(1, 'H:\\\\minjae\\\\Trying Obama Dataset\\\\data_processing')\n",
    "from tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "expected-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OUTPUT = 204 # 68 x coordinate + 68 y coordinate + 68 z coordinate\n",
    "WINDOW_LENGTH = 50 # in miliseconds\n",
    "FEATURES = \"MFCC\"\n",
    "N_INPUT = 26 # Number of MFCC features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interesting-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(input_vectors):\n",
    "    \"\"\"\n",
    "    Pad array of features in order to be able to take context at each time-frame\n",
    "    We pad N_CONTEXT / 2 frames before and after the signal by the features of the silence\n",
    "    Args:\n",
    "        input_vectors:      feature vectors for an audio\n",
    "\n",
    "    Returns:\n",
    "        new_input_vectors:  padded feature vectors\n",
    "    \"\"\"\n",
    "\n",
    "    if FEATURES == \"MFCC\":\n",
    "\n",
    "        # Pad sequence not with zeros but with MFCC of the silence\n",
    "\n",
    "        silence_vectors = calculate_mfcc(\"data_processing/silence.wav\")\n",
    "        mfcc_empty_vector = silence_vectors[0]\n",
    "\n",
    "        empty_vectors = np.array([mfcc_empty_vector] * int(N_CONTEXT / 2))\n",
    "\n",
    "    # append N_CONTEXT/2 \"empty\" mfcc vectors to past\n",
    "    new_input_vectors = np.append(empty_vectors, input_vectors, axis=0)\n",
    "    # append N_CONTEXT/2 \"empty\" mfcc vectors to future\n",
    "    new_input_vectors = np.append(new_input_vectors, empty_vectors, axis=0)\n",
    "\n",
    "    return new_input_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "weighted-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_sequences(dataset):\n",
    "    \"\"\"\n",
    "    Create test sequences\n",
    "    Args:\n",
    "        nodes:    markers used in motion caption\n",
    "        dataset:  dataset name ('train', 'test' or 'dev')\n",
    "\n",
    "    Returns:\n",
    "        nothing, saves dataset into .npy file\n",
    "\n",
    "    \"\"\"\n",
    "    DATA_FILE = pd.read_csv(DATA_DIR + '/gg-'+dataset+'.csv')\n",
    "\n",
    "    for i in range(len(DATA_FILE)):\n",
    "#         input_vectors, output_vectors = create_vectors(DATA_FILE['wav_filename'][i], DATA_FILE['bvh_filename'][i])\n",
    "        input_vectors, output_vectors = create_vectors(DATA_FILE['wav_filename'][i], DATA_FILE['csv_filename'][i])\n",
    "\n",
    "        array = DATA_FILE['wav_filename'][i].split(\"/\")\n",
    "        name = array[len(array)-1].split(\".\")[0].split('\\\\')[-1]\n",
    "        X = input_vectors\n",
    "#         print(\"name:\", name)\n",
    "        if not os.path.isdir(DATA_DIR + '/'+dataset+'_inputs'):\n",
    "            os.makedirs(DATA_DIR +  '/'+dataset+'_inputs')\n",
    "\n",
    "        x_file_name = DATA_DIR + '/'+dataset+'_inputs/X_test_' + name + '.npy'\n",
    "\n",
    "        np.save(x_file_name, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ahead-paper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create(name):\n",
    "    \"\"\"\n",
    "    Create a dataset\n",
    "    Args:\n",
    "        name:  dataset: 'train' or 'test' or 'dev\n",
    "        nodes: markers used in motion caption\n",
    "\n",
    "    Returns:\n",
    "        nothing: saves numpy arrays of the features and labels as .npy files\n",
    "\n",
    "    \"\"\"\n",
    "    DATA_FILE = pd.read_csv(DATA_DIR + '/gg-' + str(name) + '.csv')\n",
    "    X = np.array([])\n",
    "    Y = np.array([])\n",
    "\n",
    "    for i in range(len(DATA_FILE)):\n",
    "        input_vectors, output_vectors = create_vectors(DATA_FILE['wav_filename'][i], DATA_FILE['csv_filename'][i])\n",
    "\n",
    "        if len(X) == 0:\n",
    "            X = input_vectors\n",
    "            Y = output_vectors\n",
    "        else:\n",
    "            X = np.concatenate((X, input_vectors), axis=0)\n",
    "            Y = np.concatenate((Y, output_vectors), axis=0)\n",
    "\n",
    "        if i%3==0:\n",
    "            print(\"^^^^^^^^^^^^^^^^^^\")\n",
    "            print('{:.2f}% of processing for {:.8} dataset is done'.format(100.0 * (i+1) / len(DATA_FILE), str(name)))\n",
    "            print(\"Current dataset sizes are:\")\n",
    "            print(X.shape)\n",
    "            print(Y.shape)\n",
    "\n",
    "    x_file_name = DATA_DIR + '/X_' + str(name) + '.npy'\n",
    "    y_file_name = DATA_DIR + '/Y_' + str(name) + '.npy'\n",
    "    np.save(x_file_name, X)\n",
    "    np.save(y_file_name, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alternative-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def create_vectors(audio_filename, gesture_filename):\n",
    "    \"\"\"\n",
    "    Extract features from a given pair of audio and motion files\n",
    "    Args:\n",
    "        audio_filename:    file name for an audio file (.wav)\n",
    "        gesture_filename:  file name for a motion file (.csv)\n",
    "        nodes:             an array of markers for the motion\n",
    "\n",
    "    Returns:\n",
    "        input_with_context   : speech features\n",
    "        output_with_context  : motion features\n",
    "    \"\"\"\n",
    "    # Step 1: Vactorizing speech, with features of N_INPUT dimension, time steps of 0.01s\n",
    "    # and window length with 0.025s => results in an array of 100 x N_INPUT\n",
    "    AUs = [1, 2, 4, 5, 6, 7, 9, 10, 12, 14, 15, 17, 20, 23, 25, 26, 45] # 17 features\n",
    "    \n",
    "    \n",
    "    if FEATURES == \"MFCC\":\n",
    "\n",
    "        input_vectors = calculate_mfcc(audio_filename)\n",
    "#         print(\"input_vectors:\",input_vectors)\n",
    "#         print(len(input_vectors))\n",
    "#         print(\"shape of input_vectors:\", input_vectors.shape)\n",
    "\n",
    "    \n",
    "    # Step 2: Read motions\n",
    "\n",
    "    motion_format = \"csv\"\n",
    "\n",
    "    if motion_format == \"csv\":\n",
    "        df = pd.read_csv(gesture_filename, delimiter=',', encoding=\"utf-8\")\n",
    "        frametime = df.shape[0]\n",
    "        \n",
    "        #downsampled to 20FPS from 30FPS\n",
    "        df = df.drop(df.index[2::3])\n",
    "        df = df.reset_index(drop=True)\n",
    "        \n",
    "#         print(\"df[0]:\", df.iloc[0])\n",
    "#         output_vectors = np.array([[],[]])\n",
    "        length_df = frametime\n",
    "        output_vectors = np.zeros(shape=(length_df,N_OUTPUT))\n",
    "        column_regex_pattern = re.compile(r'^ [XYZ]_[0-9]*')\n",
    "#         print('x_regex_pattern:',x_regex_pattern)\n",
    "        columns = df.columns[df.columns.str.contains(column_regex_pattern)]\n",
    "        output_vectors = df[columns].values\n",
    "            \n",
    "    \n",
    "    \n",
    "    # Step 3: Align vector length\n",
    "    input_vectors, output_vectors = shorten(input_vectors, output_vectors)\n",
    "\n",
    "    \n",
    "    # Step 4: Retrieve N_CONTEXT each time, stride one by one\n",
    "    input_with_context = np.array([])\n",
    "    output_with_context = np.array([])\n",
    "\n",
    "    strides = len(input_vectors)\n",
    "\n",
    "    input_vectors = pad_sequence(input_vectors)\n",
    "    \n",
    "#     print(\"input_vectors_after_padding:\", input_vectors)\n",
    "#     print(\"shape of input_vectors_after_padding:\", input_vectors.shape)\n",
    "    \n",
    "    for i in range(strides):\n",
    "        stride = i + int(N_CONTEXT/2)\n",
    "        if i == 0:\n",
    "            input_with_context = input_vectors[stride - int(N_CONTEXT/2) : stride + int(N_CONTEXT/2) + 1].reshape(1, N_CONTEXT+1, N_INPUT)\n",
    "            output_with_context = output_vectors[i].reshape(1, N_OUTPUT)\n",
    "        else:\n",
    "            input_with_context = np.append(input_with_context, input_vectors[stride - int(N_CONTEXT/2) : stride + int(N_CONTEXT/2) + 1].reshape(1, N_CONTEXT+1, N_INPUT), axis=0)\n",
    "            output_with_context = np.append(output_with_context, output_vectors[i].reshape(1, N_OUTPUT), axis=0)\n",
    "    \n",
    "    return input_with_context, output_with_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "driving-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data_3d_cord'\n",
    "N_CONTEXT = 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "superior-seven",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (960) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (882) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-171038bd2152>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dev'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-74b2e6c84210>\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_FILE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0minput_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_vectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_vectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_FILE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'wav_filename'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDATA_FILE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csv_filename'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-75aef108b6a2>\u001b[0m in \u001b[0;36mcreate_vectors\u001b[1;34m(audio_filename, gesture_filename)\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0moutput_with_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_vectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_OUTPUT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[0minput_with_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_with_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_vectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstride\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_CONTEXT\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mstride\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_CONTEXT\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_CONTEXT\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_INPUT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m             \u001b[0moutput_with_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_with_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_vectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_OUTPUT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mappend\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   4669\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4670\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4671\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "create('test')\n",
    "create('dev')\n",
    "create('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "treated-simulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (960) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (882) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (960) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (882) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    }
   ],
   "source": [
    "create_test_sequences('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "alternative-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = pd.read_csv(DATA_DIR + '/gg-' + str('train') + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "structural-massachusetts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>wav_filesize</th>\n",
       "      <th>csv_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>14409806</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>16961614</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>14594126</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>15577166</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>4042830</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>13533262</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>8552526</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>12877902</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>6660174</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>19148878</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>2912334</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>24522830</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>6860878</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>5640270</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>2330702</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>2244686</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>6656078</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>2433102</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>1966158</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>1028174</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>3285070</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>16601166</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>17748046</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>13701198</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>10428494</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>12689486</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>8601678</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>21213262</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>15024206</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>6058062</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>4071502</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>1028174</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>9044046</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>20889678</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>21373006</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>9035854</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>5197902</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>22585422</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>12578894</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>9904206</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...</td>\n",
       "      <td>21426254</td>\n",
       "      <td>H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         wav_filename  wav_filesize  \\\n",
       "0   H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...      14409806   \n",
       "1   H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...      16961614   \n",
       "2   H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...      14594126   \n",
       "3   H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...      15577166   \n",
       "4   H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...       4042830   \n",
       "5   H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...      13533262   \n",
       "6   H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...       8552526   \n",
       "7   H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...      12877902   \n",
       "8   H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...       6660174   \n",
       "9   H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...      19148878   \n",
       "10  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...       2912334   \n",
       "11  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...      24522830   \n",
       "12  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...       6860878   \n",
       "13  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...       5640270   \n",
       "14  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...       2330702   \n",
       "15  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...       2244686   \n",
       "16  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...       6656078   \n",
       "17  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...       2433102   \n",
       "18  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...       1966158   \n",
       "19  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...       1028174   \n",
       "20  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...       3285070   \n",
       "21  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...      16601166   \n",
       "22  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...      17748046   \n",
       "23  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...      13701198   \n",
       "24  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...      10428494   \n",
       "25  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...      12689486   \n",
       "26  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...       8601678   \n",
       "27  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...      21213262   \n",
       "28  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...      15024206   \n",
       "29  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...       6058062   \n",
       "30  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...       4071502   \n",
       "31  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...       1028174   \n",
       "32  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...       9044046   \n",
       "33  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...      20889678   \n",
       "34  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...      21373006   \n",
       "35  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...       9035854   \n",
       "36  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...       5197902   \n",
       "37  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...      22585422   \n",
       "38  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...      12578894   \n",
       "39  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...       9904206   \n",
       "40  H:\\minjae\\Trying Obama Dataset\\data\\train\\inpu...      21426254   \n",
       "\n",
       "                                         csv_filename  \n",
       "0   H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "1   H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "2   H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "3   H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "4   H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "5   H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "6   H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "7   H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "8   H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "9   H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "10  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "11  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "12  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "13  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "14  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "15  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "16  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "17  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "18  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "19  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "20  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "21  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "22  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "23  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "24  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "25  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "26  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "27  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "28  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "29  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "30  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "31  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "32  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "33  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "34  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "35  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "36  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "37  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "38  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "39  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  \n",
       "40  H:\\minjae\\Trying Obama Dataset\\data\\train\\labe...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "breathing-eligibility",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-bb304542d89d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1369\u001b[0m         )\n\u001b[0;32m   1370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    645\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    648\u001b[0m             )\n\u001b[0;32m    649\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'data'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data', delimiter=',', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "passive-canvas",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train/labels/pose1.csv', delimiter=',', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "final-sperm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_regex_pattern: re.compile('^ x_[0-9]*')\n",
      "x_columns: Index([' x_0', ' x_1', ' x_2', ' x_3', ' x_4', ' x_5', ' x_6', ' x_7', ' x_8',\n",
      "       ' x_9', ' x_10', ' x_11', ' x_12', ' x_13', ' x_14', ' x_15', ' x_16',\n",
      "       ' x_17', ' x_18', ' x_19', ' x_20', ' x_21', ' x_22', ' x_23', ' x_24',\n",
      "       ' x_25', ' x_26', ' x_27', ' x_28', ' x_29', ' x_30', ' x_31', ' x_32',\n",
      "       ' x_33', ' x_34', ' x_35', ' x_36', ' x_37', ' x_38', ' x_39', ' x_40',\n",
      "       ' x_41', ' x_42', ' x_43', ' x_44', ' x_45', ' x_46', ' x_47', ' x_48',\n",
      "       ' x_49', ' x_50', ' x_51', ' x_52', ' x_53', ' x_54', ' x_55', ' x_56',\n",
      "       ' x_57', ' x_58', ' x_59', ' x_60', ' x_61', ' x_62', ' x_63', ' x_64',\n",
      "       ' x_65', ' x_66', ' x_67'],\n",
      "      dtype='object')\n",
      "y_columns: Index([' x_0', ' x_1', ' x_2', ' x_3', ' x_4', ' x_5', ' x_6', ' x_7', ' x_8',\n",
      "       ' x_9',\n",
      "       ...\n",
      "       ' y_58', ' y_59', ' y_60', ' y_61', ' y_62', ' y_63', ' y_64', ' y_65',\n",
      "       ' y_66', ' y_67'],\n",
      "      dtype='object', length=136)\n"
     ]
    }
   ],
   "source": [
    "x_regex_pattern = re.compile(r'^ x_[0-9]*')\n",
    "y_regex_pattern = re.compile(r'^ [xy]_[0-9]*')\n",
    "print('x_regex_pattern:',x_regex_pattern)\n",
    "x_columns = df.columns[df.columns.str.contains(x_regex_pattern)]\n",
    "y_columns = df.columns[df.columns.str.contains(y_regex_pattern)]\n",
    "print(\"x_columns:\", x_columns)\n",
    "print(\"y_columns:\", y_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "given-chorus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " x_0     369.0\n",
       " x_1     371.7\n",
       " x_2     376.7\n",
       " x_3     383.9\n",
       " x_4     394.6\n",
       "         ...  \n",
       " x_63    472.8\n",
       " x_64    493.9\n",
       " x_65    474.1\n",
       " x_66    463.5\n",
       " x_67    453.7\n",
       "Name: 0, Length: 68, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[x_columns].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fantastic-kruger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>...</th>\n",
       "      <th>x_58</th>\n",
       "      <th>x_59</th>\n",
       "      <th>x_60</th>\n",
       "      <th>x_61</th>\n",
       "      <th>x_62</th>\n",
       "      <th>x_63</th>\n",
       "      <th>x_64</th>\n",
       "      <th>x_65</th>\n",
       "      <th>x_66</th>\n",
       "      <th>x_67</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>369.0</td>\n",
       "      <td>371.7</td>\n",
       "      <td>376.7</td>\n",
       "      <td>383.9</td>\n",
       "      <td>394.6</td>\n",
       "      <td>409.5</td>\n",
       "      <td>425.2</td>\n",
       "      <td>444.7</td>\n",
       "      <td>466.4</td>\n",
       "      <td>486.9</td>\n",
       "      <td>...</td>\n",
       "      <td>455.1</td>\n",
       "      <td>441.1</td>\n",
       "      <td>433.6</td>\n",
       "      <td>453.0</td>\n",
       "      <td>462.4</td>\n",
       "      <td>472.8</td>\n",
       "      <td>493.9</td>\n",
       "      <td>474.1</td>\n",
       "      <td>463.5</td>\n",
       "      <td>453.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>369.2</td>\n",
       "      <td>372.0</td>\n",
       "      <td>377.1</td>\n",
       "      <td>384.4</td>\n",
       "      <td>395.4</td>\n",
       "      <td>410.5</td>\n",
       "      <td>426.1</td>\n",
       "      <td>445.3</td>\n",
       "      <td>466.7</td>\n",
       "      <td>487.1</td>\n",
       "      <td>...</td>\n",
       "      <td>455.0</td>\n",
       "      <td>440.9</td>\n",
       "      <td>433.3</td>\n",
       "      <td>453.0</td>\n",
       "      <td>462.4</td>\n",
       "      <td>472.7</td>\n",
       "      <td>494.3</td>\n",
       "      <td>473.9</td>\n",
       "      <td>463.4</td>\n",
       "      <td>453.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>369.0</td>\n",
       "      <td>371.9</td>\n",
       "      <td>377.2</td>\n",
       "      <td>384.5</td>\n",
       "      <td>395.4</td>\n",
       "      <td>410.4</td>\n",
       "      <td>426.1</td>\n",
       "      <td>445.6</td>\n",
       "      <td>467.1</td>\n",
       "      <td>487.5</td>\n",
       "      <td>...</td>\n",
       "      <td>454.8</td>\n",
       "      <td>440.8</td>\n",
       "      <td>433.3</td>\n",
       "      <td>452.8</td>\n",
       "      <td>462.3</td>\n",
       "      <td>472.7</td>\n",
       "      <td>494.4</td>\n",
       "      <td>474.0</td>\n",
       "      <td>463.4</td>\n",
       "      <td>453.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>369.1</td>\n",
       "      <td>371.8</td>\n",
       "      <td>377.0</td>\n",
       "      <td>384.3</td>\n",
       "      <td>395.1</td>\n",
       "      <td>410.0</td>\n",
       "      <td>425.9</td>\n",
       "      <td>445.5</td>\n",
       "      <td>467.1</td>\n",
       "      <td>487.6</td>\n",
       "      <td>...</td>\n",
       "      <td>454.6</td>\n",
       "      <td>440.5</td>\n",
       "      <td>433.0</td>\n",
       "      <td>452.6</td>\n",
       "      <td>462.2</td>\n",
       "      <td>472.8</td>\n",
       "      <td>494.5</td>\n",
       "      <td>474.0</td>\n",
       "      <td>463.2</td>\n",
       "      <td>453.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>369.1</td>\n",
       "      <td>371.8</td>\n",
       "      <td>376.9</td>\n",
       "      <td>384.1</td>\n",
       "      <td>394.9</td>\n",
       "      <td>409.9</td>\n",
       "      <td>425.6</td>\n",
       "      <td>445.1</td>\n",
       "      <td>466.6</td>\n",
       "      <td>487.1</td>\n",
       "      <td>...</td>\n",
       "      <td>454.4</td>\n",
       "      <td>440.3</td>\n",
       "      <td>432.8</td>\n",
       "      <td>452.5</td>\n",
       "      <td>462.0</td>\n",
       "      <td>472.6</td>\n",
       "      <td>494.3</td>\n",
       "      <td>473.7</td>\n",
       "      <td>463.0</td>\n",
       "      <td>453.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244</th>\n",
       "      <td>393.0</td>\n",
       "      <td>389.7</td>\n",
       "      <td>388.8</td>\n",
       "      <td>390.7</td>\n",
       "      <td>397.3</td>\n",
       "      <td>408.3</td>\n",
       "      <td>421.0</td>\n",
       "      <td>439.4</td>\n",
       "      <td>461.3</td>\n",
       "      <td>482.3</td>\n",
       "      <td>...</td>\n",
       "      <td>464.4</td>\n",
       "      <td>450.3</td>\n",
       "      <td>442.5</td>\n",
       "      <td>467.3</td>\n",
       "      <td>477.5</td>\n",
       "      <td>488.8</td>\n",
       "      <td>506.6</td>\n",
       "      <td>487.4</td>\n",
       "      <td>476.0</td>\n",
       "      <td>465.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>392.5</td>\n",
       "      <td>389.2</td>\n",
       "      <td>388.4</td>\n",
       "      <td>390.4</td>\n",
       "      <td>397.0</td>\n",
       "      <td>407.9</td>\n",
       "      <td>420.7</td>\n",
       "      <td>439.0</td>\n",
       "      <td>460.9</td>\n",
       "      <td>481.8</td>\n",
       "      <td>...</td>\n",
       "      <td>464.2</td>\n",
       "      <td>450.2</td>\n",
       "      <td>442.2</td>\n",
       "      <td>466.7</td>\n",
       "      <td>476.8</td>\n",
       "      <td>488.1</td>\n",
       "      <td>506.0</td>\n",
       "      <td>486.9</td>\n",
       "      <td>475.6</td>\n",
       "      <td>465.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>392.3</td>\n",
       "      <td>389.1</td>\n",
       "      <td>388.3</td>\n",
       "      <td>390.2</td>\n",
       "      <td>396.9</td>\n",
       "      <td>407.8</td>\n",
       "      <td>420.6</td>\n",
       "      <td>438.9</td>\n",
       "      <td>460.8</td>\n",
       "      <td>481.7</td>\n",
       "      <td>...</td>\n",
       "      <td>464.2</td>\n",
       "      <td>450.2</td>\n",
       "      <td>442.2</td>\n",
       "      <td>466.8</td>\n",
       "      <td>476.8</td>\n",
       "      <td>488.0</td>\n",
       "      <td>505.9</td>\n",
       "      <td>486.8</td>\n",
       "      <td>475.6</td>\n",
       "      <td>465.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>391.8</td>\n",
       "      <td>388.6</td>\n",
       "      <td>387.8</td>\n",
       "      <td>389.8</td>\n",
       "      <td>396.3</td>\n",
       "      <td>407.3</td>\n",
       "      <td>420.1</td>\n",
       "      <td>438.5</td>\n",
       "      <td>460.5</td>\n",
       "      <td>481.6</td>\n",
       "      <td>...</td>\n",
       "      <td>463.3</td>\n",
       "      <td>449.5</td>\n",
       "      <td>441.5</td>\n",
       "      <td>465.7</td>\n",
       "      <td>475.7</td>\n",
       "      <td>486.9</td>\n",
       "      <td>504.9</td>\n",
       "      <td>485.9</td>\n",
       "      <td>474.7</td>\n",
       "      <td>464.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>391.0</td>\n",
       "      <td>387.9</td>\n",
       "      <td>387.3</td>\n",
       "      <td>389.4</td>\n",
       "      <td>396.1</td>\n",
       "      <td>407.3</td>\n",
       "      <td>420.1</td>\n",
       "      <td>438.4</td>\n",
       "      <td>460.5</td>\n",
       "      <td>481.6</td>\n",
       "      <td>...</td>\n",
       "      <td>462.3</td>\n",
       "      <td>448.8</td>\n",
       "      <td>441.1</td>\n",
       "      <td>464.4</td>\n",
       "      <td>474.6</td>\n",
       "      <td>486.1</td>\n",
       "      <td>503.9</td>\n",
       "      <td>485.2</td>\n",
       "      <td>473.8</td>\n",
       "      <td>463.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2249 rows  68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_0    x_1    x_2    x_3    x_4    x_5    x_6    x_7    x_8    x_9  \\\n",
       "0     369.0  371.7  376.7  383.9  394.6  409.5  425.2  444.7  466.4  486.9   \n",
       "1     369.2  372.0  377.1  384.4  395.4  410.5  426.1  445.3  466.7  487.1   \n",
       "2     369.0  371.9  377.2  384.5  395.4  410.4  426.1  445.6  467.1  487.5   \n",
       "3     369.1  371.8  377.0  384.3  395.1  410.0  425.9  445.5  467.1  487.6   \n",
       "4     369.1  371.8  376.9  384.1  394.9  409.9  425.6  445.1  466.6  487.1   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "2244  393.0  389.7  388.8  390.7  397.3  408.3  421.0  439.4  461.3  482.3   \n",
       "2245  392.5  389.2  388.4  390.4  397.0  407.9  420.7  439.0  460.9  481.8   \n",
       "2246  392.3  389.1  388.3  390.2  396.9  407.8  420.6  438.9  460.8  481.7   \n",
       "2247  391.8  388.6  387.8  389.8  396.3  407.3  420.1  438.5  460.5  481.6   \n",
       "2248  391.0  387.9  387.3  389.4  396.1  407.3  420.1  438.4  460.5  481.6   \n",
       "\n",
       "      ...   x_58   x_59   x_60   x_61   x_62   x_63   x_64   x_65   x_66  \\\n",
       "0     ...  455.1  441.1  433.6  453.0  462.4  472.8  493.9  474.1  463.5   \n",
       "1     ...  455.0  440.9  433.3  453.0  462.4  472.7  494.3  473.9  463.4   \n",
       "2     ...  454.8  440.8  433.3  452.8  462.3  472.7  494.4  474.0  463.4   \n",
       "3     ...  454.6  440.5  433.0  452.6  462.2  472.8  494.5  474.0  463.2   \n",
       "4     ...  454.4  440.3  432.8  452.5  462.0  472.6  494.3  473.7  463.0   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "2244  ...  464.4  450.3  442.5  467.3  477.5  488.8  506.6  487.4  476.0   \n",
       "2245  ...  464.2  450.2  442.2  466.7  476.8  488.1  506.0  486.9  475.6   \n",
       "2246  ...  464.2  450.2  442.2  466.8  476.8  488.0  505.9  486.8  475.6   \n",
       "2247  ...  463.3  449.5  441.5  465.7  475.7  486.9  504.9  485.9  474.7   \n",
       "2248  ...  462.3  448.8  441.1  464.4  474.6  486.1  503.9  485.2  473.8   \n",
       "\n",
       "       x_67  \n",
       "0     453.7  \n",
       "1     453.7  \n",
       "2     453.6  \n",
       "3     453.3  \n",
       "4     453.1  \n",
       "...     ...  \n",
       "2244  465.5  \n",
       "2245  465.2  \n",
       "2246  465.3  \n",
       "2247  464.4  \n",
       "2248  463.3  \n",
       "\n",
       "[2249 rows x 68 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[x_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "distinguished-polyester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>...</th>\n",
       "      <th>y_58</th>\n",
       "      <th>y_59</th>\n",
       "      <th>y_60</th>\n",
       "      <th>y_61</th>\n",
       "      <th>y_62</th>\n",
       "      <th>y_63</th>\n",
       "      <th>y_64</th>\n",
       "      <th>y_65</th>\n",
       "      <th>y_66</th>\n",
       "      <th>y_67</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>369.0</td>\n",
       "      <td>371.7</td>\n",
       "      <td>376.7</td>\n",
       "      <td>383.9</td>\n",
       "      <td>394.6</td>\n",
       "      <td>409.5</td>\n",
       "      <td>425.2</td>\n",
       "      <td>444.7</td>\n",
       "      <td>466.4</td>\n",
       "      <td>486.9</td>\n",
       "      <td>...</td>\n",
       "      <td>288.1</td>\n",
       "      <td>283.9</td>\n",
       "      <td>271.3</td>\n",
       "      <td>264.0</td>\n",
       "      <td>263.8</td>\n",
       "      <td>261.7</td>\n",
       "      <td>264.2</td>\n",
       "      <td>273.6</td>\n",
       "      <td>276.0</td>\n",
       "      <td>275.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>369.2</td>\n",
       "      <td>372.0</td>\n",
       "      <td>377.1</td>\n",
       "      <td>384.4</td>\n",
       "      <td>395.4</td>\n",
       "      <td>410.5</td>\n",
       "      <td>426.1</td>\n",
       "      <td>445.3</td>\n",
       "      <td>466.7</td>\n",
       "      <td>487.1</td>\n",
       "      <td>...</td>\n",
       "      <td>287.7</td>\n",
       "      <td>283.7</td>\n",
       "      <td>271.4</td>\n",
       "      <td>264.2</td>\n",
       "      <td>264.0</td>\n",
       "      <td>261.8</td>\n",
       "      <td>264.1</td>\n",
       "      <td>273.2</td>\n",
       "      <td>275.7</td>\n",
       "      <td>275.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>369.0</td>\n",
       "      <td>371.9</td>\n",
       "      <td>377.2</td>\n",
       "      <td>384.5</td>\n",
       "      <td>395.4</td>\n",
       "      <td>410.4</td>\n",
       "      <td>426.1</td>\n",
       "      <td>445.6</td>\n",
       "      <td>467.1</td>\n",
       "      <td>487.5</td>\n",
       "      <td>...</td>\n",
       "      <td>288.0</td>\n",
       "      <td>283.8</td>\n",
       "      <td>271.4</td>\n",
       "      <td>264.1</td>\n",
       "      <td>263.8</td>\n",
       "      <td>261.6</td>\n",
       "      <td>264.1</td>\n",
       "      <td>273.5</td>\n",
       "      <td>276.0</td>\n",
       "      <td>275.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>369.1</td>\n",
       "      <td>371.8</td>\n",
       "      <td>377.0</td>\n",
       "      <td>384.3</td>\n",
       "      <td>395.1</td>\n",
       "      <td>410.0</td>\n",
       "      <td>425.9</td>\n",
       "      <td>445.5</td>\n",
       "      <td>467.1</td>\n",
       "      <td>487.6</td>\n",
       "      <td>...</td>\n",
       "      <td>287.6</td>\n",
       "      <td>283.6</td>\n",
       "      <td>271.4</td>\n",
       "      <td>264.2</td>\n",
       "      <td>264.0</td>\n",
       "      <td>261.7</td>\n",
       "      <td>264.1</td>\n",
       "      <td>273.1</td>\n",
       "      <td>275.6</td>\n",
       "      <td>275.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>369.1</td>\n",
       "      <td>371.8</td>\n",
       "      <td>376.9</td>\n",
       "      <td>384.1</td>\n",
       "      <td>394.9</td>\n",
       "      <td>409.9</td>\n",
       "      <td>425.6</td>\n",
       "      <td>445.1</td>\n",
       "      <td>466.6</td>\n",
       "      <td>487.1</td>\n",
       "      <td>...</td>\n",
       "      <td>287.6</td>\n",
       "      <td>283.5</td>\n",
       "      <td>271.4</td>\n",
       "      <td>264.4</td>\n",
       "      <td>264.2</td>\n",
       "      <td>262.0</td>\n",
       "      <td>264.2</td>\n",
       "      <td>273.0</td>\n",
       "      <td>275.5</td>\n",
       "      <td>275.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244</th>\n",
       "      <td>393.0</td>\n",
       "      <td>389.7</td>\n",
       "      <td>388.8</td>\n",
       "      <td>390.7</td>\n",
       "      <td>397.3</td>\n",
       "      <td>408.3</td>\n",
       "      <td>421.0</td>\n",
       "      <td>439.4</td>\n",
       "      <td>461.3</td>\n",
       "      <td>482.3</td>\n",
       "      <td>...</td>\n",
       "      <td>288.9</td>\n",
       "      <td>282.2</td>\n",
       "      <td>269.7</td>\n",
       "      <td>268.2</td>\n",
       "      <td>270.4</td>\n",
       "      <td>270.6</td>\n",
       "      <td>277.1</td>\n",
       "      <td>280.4</td>\n",
       "      <td>280.3</td>\n",
       "      <td>277.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>392.5</td>\n",
       "      <td>389.2</td>\n",
       "      <td>388.4</td>\n",
       "      <td>390.4</td>\n",
       "      <td>397.0</td>\n",
       "      <td>407.9</td>\n",
       "      <td>420.7</td>\n",
       "      <td>439.0</td>\n",
       "      <td>460.9</td>\n",
       "      <td>481.8</td>\n",
       "      <td>...</td>\n",
       "      <td>288.6</td>\n",
       "      <td>282.2</td>\n",
       "      <td>270.4</td>\n",
       "      <td>269.1</td>\n",
       "      <td>271.3</td>\n",
       "      <td>271.4</td>\n",
       "      <td>277.5</td>\n",
       "      <td>279.9</td>\n",
       "      <td>279.8</td>\n",
       "      <td>277.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>392.3</td>\n",
       "      <td>389.1</td>\n",
       "      <td>388.3</td>\n",
       "      <td>390.2</td>\n",
       "      <td>396.9</td>\n",
       "      <td>407.8</td>\n",
       "      <td>420.6</td>\n",
       "      <td>438.9</td>\n",
       "      <td>460.8</td>\n",
       "      <td>481.7</td>\n",
       "      <td>...</td>\n",
       "      <td>288.6</td>\n",
       "      <td>282.2</td>\n",
       "      <td>270.4</td>\n",
       "      <td>269.1</td>\n",
       "      <td>271.3</td>\n",
       "      <td>271.4</td>\n",
       "      <td>277.5</td>\n",
       "      <td>279.8</td>\n",
       "      <td>279.8</td>\n",
       "      <td>277.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>391.8</td>\n",
       "      <td>388.6</td>\n",
       "      <td>387.8</td>\n",
       "      <td>389.8</td>\n",
       "      <td>396.3</td>\n",
       "      <td>407.3</td>\n",
       "      <td>420.1</td>\n",
       "      <td>438.5</td>\n",
       "      <td>460.5</td>\n",
       "      <td>481.6</td>\n",
       "      <td>...</td>\n",
       "      <td>287.7</td>\n",
       "      <td>281.7</td>\n",
       "      <td>270.6</td>\n",
       "      <td>269.6</td>\n",
       "      <td>271.7</td>\n",
       "      <td>271.8</td>\n",
       "      <td>277.7</td>\n",
       "      <td>279.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>276.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>391.0</td>\n",
       "      <td>387.9</td>\n",
       "      <td>387.3</td>\n",
       "      <td>389.4</td>\n",
       "      <td>396.1</td>\n",
       "      <td>407.3</td>\n",
       "      <td>420.1</td>\n",
       "      <td>438.4</td>\n",
       "      <td>460.5</td>\n",
       "      <td>481.6</td>\n",
       "      <td>...</td>\n",
       "      <td>287.1</td>\n",
       "      <td>281.3</td>\n",
       "      <td>271.1</td>\n",
       "      <td>270.1</td>\n",
       "      <td>272.3</td>\n",
       "      <td>272.4</td>\n",
       "      <td>278.1</td>\n",
       "      <td>278.6</td>\n",
       "      <td>278.6</td>\n",
       "      <td>276.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2249 rows  136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_0    x_1    x_2    x_3    x_4    x_5    x_6    x_7    x_8    x_9  \\\n",
       "0     369.0  371.7  376.7  383.9  394.6  409.5  425.2  444.7  466.4  486.9   \n",
       "1     369.2  372.0  377.1  384.4  395.4  410.5  426.1  445.3  466.7  487.1   \n",
       "2     369.0  371.9  377.2  384.5  395.4  410.4  426.1  445.6  467.1  487.5   \n",
       "3     369.1  371.8  377.0  384.3  395.1  410.0  425.9  445.5  467.1  487.6   \n",
       "4     369.1  371.8  376.9  384.1  394.9  409.9  425.6  445.1  466.6  487.1   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "2244  393.0  389.7  388.8  390.7  397.3  408.3  421.0  439.4  461.3  482.3   \n",
       "2245  392.5  389.2  388.4  390.4  397.0  407.9  420.7  439.0  460.9  481.8   \n",
       "2246  392.3  389.1  388.3  390.2  396.9  407.8  420.6  438.9  460.8  481.7   \n",
       "2247  391.8  388.6  387.8  389.8  396.3  407.3  420.1  438.5  460.5  481.6   \n",
       "2248  391.0  387.9  387.3  389.4  396.1  407.3  420.1  438.4  460.5  481.6   \n",
       "\n",
       "      ...   y_58   y_59   y_60   y_61   y_62   y_63   y_64   y_65   y_66  \\\n",
       "0     ...  288.1  283.9  271.3  264.0  263.8  261.7  264.2  273.6  276.0   \n",
       "1     ...  287.7  283.7  271.4  264.2  264.0  261.8  264.1  273.2  275.7   \n",
       "2     ...  288.0  283.8  271.4  264.1  263.8  261.6  264.1  273.5  276.0   \n",
       "3     ...  287.6  283.6  271.4  264.2  264.0  261.7  264.1  273.1  275.6   \n",
       "4     ...  287.6  283.5  271.4  264.4  264.2  262.0  264.2  273.0  275.5   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "2244  ...  288.9  282.2  269.7  268.2  270.4  270.6  277.1  280.4  280.3   \n",
       "2245  ...  288.6  282.2  270.4  269.1  271.3  271.4  277.5  279.9  279.8   \n",
       "2246  ...  288.6  282.2  270.4  269.1  271.3  271.4  277.5  279.8  279.8   \n",
       "2247  ...  287.7  281.7  270.6  269.6  271.7  271.8  277.7  279.0  279.0   \n",
       "2248  ...  287.1  281.3  271.1  270.1  272.3  272.4  278.1  278.6  278.6   \n",
       "\n",
       "       y_67  \n",
       "0     275.9  \n",
       "1     275.6  \n",
       "2     275.8  \n",
       "3     275.4  \n",
       "4     275.3  \n",
       "...     ...  \n",
       "2244  277.8  \n",
       "2245  277.4  \n",
       "2246  277.3  \n",
       "2247  276.5  \n",
       "2248  276.1  \n",
       "\n",
       "[2249 rows x 136 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[y_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "brilliant-image",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2249"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "individual-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_vectors = np.zeros(shape=(len(df),N_OUTPUT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eligible-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_vectors = df[y_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "homeless-prison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[369. , 371.7, 376.7, ..., 273.6, 276. , 275.9],\n",
       "       [369.2, 372. , 377.1, ..., 273.2, 275.7, 275.6],\n",
       "       [369. , 371.9, 377.2, ..., 273.5, 276. , 275.8],\n",
       "       ...,\n",
       "       [392.3, 389.1, 388.3, ..., 279.8, 279.8, 277.3],\n",
       "       [391.8, 388.6, 387.8, ..., 279. , 279. , 276.5],\n",
       "       [391. , 387.9, 387.3, ..., 278.6, 278.6, 276.1]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-quarterly",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
