{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "equipped-houston",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "harmful-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import pandas\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "blond-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "NUM_OF_TEST = 3\n",
    "FIRST_DATA_ID = 1\n",
    "LAST_DATA_ID = 45\n",
    "\n",
    "# NUM_OF_TEST = 90\n",
    "# FIRST_DATA_ID = 20\n",
    "# LAST_DATA_ID = 1182\n",
    "\n",
    "\n",
    "AUGMENT = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "quarterly-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_and_format_data(data_dir):\n",
    "\n",
    "    if not os.path.isdir(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    _download_datasets(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "creative-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _download_datasets(data_dir):\n",
    "\n",
    "    _create_dir(data_dir)\n",
    "\n",
    "    # prepare training data (including validation data)\n",
    "    for i in range (FIRST_DATA_ID, LAST_DATA_ID - NUM_OF_TEST):\n",
    "        filename = \"audio\" + str(i) + \".wav\"\n",
    "        original_file_path = path.join(\"dataset/speech/\" + filename)\n",
    "        if os.path.exists(original_file_path):\n",
    "            target_file_path = path.join(data_dir + \"/train/inputs/\" + filename)\n",
    "            print(target_file_path)\n",
    "            shutil.copy(original_file_path, target_file_path)\n",
    "        else:\n",
    "            print(original_file_path + \" does not exist\")\n",
    "        filename = \"pose\" + str(i) + \".csv\"\n",
    "        original_file_path = path.join(\"dataset/motion/\" + filename)\n",
    "        if os.path.exists(original_file_path):\n",
    "            target_file_path = path.join(data_dir + \"/train/labels/\" + filename)\n",
    "            print(target_file_path)\n",
    "            shutil.copy(original_file_path, target_file_path)\n",
    "        else:\n",
    "            print(original_file_path + \" does not exist\")\n",
    "\n",
    "    # prepare test data\n",
    "    for i in range(LAST_DATA_ID - NUM_OF_TEST, LAST_DATA_ID + 1,2):\n",
    "        filename = \"audio\" + str(i) + \".wav\"\n",
    "        original_file_path = path.join(\"dataset/speech/\" + filename)\n",
    "        if os.path.exists(original_file_path):\n",
    "            target_file_path = path.join(data_dir + \"/test/inputs/\" + filename)\n",
    "            print(target_file_path)\n",
    "            shutil.copy(original_file_path, target_file_path)\n",
    "        else:\n",
    "            print(original_file_path + \" does not exist\")\n",
    "        filename = \"pose\" + str(i) + \".csv\"\n",
    "        original_file_path = path.join(\"dataset/motion/\" + filename)\n",
    "        if os.path.exists(original_file_path):\n",
    "            target_file_path = path.join(data_dir + \"/test/labels/\" + filename)\n",
    "            print(target_file_path)\n",
    "            shutil.copy(original_file_path, target_file_path)\n",
    "        else:\n",
    "            print(original_file_path + \" does not exist\")\n",
    "\n",
    "    # prepare dev data (does not affect results of training at all)\n",
    "    for i in range(LAST_DATA_ID - NUM_OF_TEST + 1, LAST_DATA_ID + 1, 2):\n",
    "        filename = \"audio\" + str(i) + \".wav\"\n",
    "        original_file_path = path.join(\"dataset/speech/\" + filename)\n",
    "        if os.path.exists(original_file_path):\n",
    "            target_file_path = path.join(data_dir + \"/dev/inputs/\" + filename)\n",
    "            print(target_file_path)\n",
    "            shutil.copy(original_file_path, target_file_path)\n",
    "        else:\n",
    "            print(original_file_path + \" does not exist\")\n",
    "        filename = \"pose\" + str(i) + \".csv\"\n",
    "        original_file_path = path.join(\"dataset/motion/\" + filename)\n",
    "        if os.path.exists(original_file_path):\n",
    "            target_file_path = path.join(data_dir + \"/dev/labels/\" + filename)\n",
    "            print(target_file_path)\n",
    "            shutil.copy(original_file_path, target_file_path)\n",
    "        else:\n",
    "            print(original_file_path + \" does not exist\")\n",
    "\n",
    "    # data augmentation\n",
    "    if AUGMENT:\n",
    "        os.system('./data_processing/add_noisy_data.sh {0} {1} {2} {3}'.format(\"train\", FIRST_DATA_ID, LAST_DATA_ID-NUM_OF_TEST, data_dir))\n",
    "\n",
    "    extracted_dir = path.join(data_dir)\n",
    "\n",
    "    dev_files, train_files, test_files = _format_datasets(extracted_dir)\n",
    "\n",
    "    dev_files.to_csv(path.join(extracted_dir, \"gg-dev.csv\"), index=False)\n",
    "    train_files.to_csv(path.join(extracted_dir, \"gg-train.csv\"), index=False)\n",
    "    test_files.to_csv(path.join(extracted_dir, \"gg-test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "forty-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_dir(data_dir):\n",
    "\n",
    "    dir_names = [\"train\", \"test\", \"dev\"]\n",
    "    sub_dir_names = [\"inputs\", \"labels\"]\n",
    "\n",
    "    # create ../data_dir/[train, test, dev]/[inputs, labels]\n",
    "    for dir_name in dir_names:\n",
    "        dir_path = path.join(data_dir, dir_name)\n",
    "        print(dir_path)\n",
    "        if not os.path.isdir(dir_path):\n",
    "            os.makedirs(dir_path)  # ../data/train\n",
    "\n",
    "        for sub_dir_name in sub_dir_names:\n",
    "            dir_path = path.join(data_dir, dir_name, sub_dir_name)\n",
    "            print(dir_path)\n",
    "            if not os.path.isdir(dir_path):\n",
    "                os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ancient-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _format_datasets(extracted_dir):\n",
    "    train_files = _files_to_pandas_dataframe(extracted_dir, \"train\", range(FIRST_DATA_ID, LAST_DATA_ID - NUM_OF_TEST))\n",
    "    test_files = _files_to_pandas_dataframe(extracted_dir, \"test\", range(LAST_DATA_ID - NUM_OF_TEST, LAST_DATA_ID + 1, 2))\n",
    "    dev_files = _files_to_pandas_dataframe(extracted_dir, \"dev\", range(LAST_DATA_ID - NUM_OF_TEST+1, LAST_DATA_ID + 1,2))\n",
    "\n",
    "    return dev_files, train_files, test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "practical-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _files_to_pandas_dataframe(extracted_dir, set_name, idx_range):\n",
    "    files = []\n",
    "    for idx in idx_range:\n",
    "        # original files\n",
    "        try:\n",
    "            input_file = path.abspath(path.join(extracted_dir, set_name, \"inputs\", \"audio\" + str(idx) + \".wav\"))\n",
    "        except OSError:\n",
    "            continue\n",
    "        try:\n",
    "            label_file = path.abspath(path.join(extracted_dir, set_name, \"labels\", \"pose\" + str(idx) + \".csv\"))\n",
    "        except OSError:\n",
    "            continue\n",
    "        try:\n",
    "            wav_size = path.getsize(input_file)\n",
    "        except OSError:\n",
    "            continue\n",
    "\n",
    "        files.append((input_file, wav_size, label_file))\n",
    "\n",
    "        # noisy files\n",
    "        try:\n",
    "            noisy_input_file = path.abspath(path.join(extracted_dir, set_name, \"inputs\", \"naudio\" + str(idx) + \".wav\"))\n",
    "        except OSError:\n",
    "            continue\n",
    "        try:\n",
    "            noisy_wav_size = path.getsize(noisy_input_file)\n",
    "        except OSError:\n",
    "            continue\n",
    "        print(str(idx))\n",
    "\n",
    "        files.append((noisy_input_file, noisy_wav_size, label_file))\n",
    "\n",
    "    return pandas.DataFrame(data=files, columns=[\"wav_filename\", \"wav_filesize\", \"csv_filename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aboriginal-domestic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_3d_cord\\train\n",
      "data_3d_cord\\train\\inputs\n",
      "data_3d_cord\\train\\labels\n",
      "data_3d_cord\\test\n",
      "data_3d_cord\\test\\inputs\n",
      "data_3d_cord\\test\\labels\n",
      "data_3d_cord\\dev\n",
      "data_3d_cord\\dev\\inputs\n",
      "data_3d_cord\\dev\\labels\n",
      "data_3d_cord/train/inputs/audio1.wav\n",
      "data_3d_cord/train/labels/pose1.csv\n",
      "data_3d_cord/train/inputs/audio2.wav\n",
      "data_3d_cord/train/labels/pose2.csv\n",
      "data_3d_cord/train/inputs/audio3.wav\n",
      "data_3d_cord/train/labels/pose3.csv\n",
      "data_3d_cord/train/inputs/audio4.wav\n",
      "data_3d_cord/train/labels/pose4.csv\n",
      "data_3d_cord/train/inputs/audio5.wav\n",
      "data_3d_cord/train/labels/pose5.csv\n",
      "data_3d_cord/train/inputs/audio6.wav\n",
      "data_3d_cord/train/labels/pose6.csv\n",
      "data_3d_cord/train/inputs/audio7.wav\n",
      "data_3d_cord/train/labels/pose7.csv\n",
      "dataset/speech/audio8.wav does not exist\n",
      "dataset/motion/pose8.csv does not exist\n",
      "data_3d_cord/train/inputs/audio9.wav\n",
      "data_3d_cord/train/labels/pose9.csv\n",
      "data_3d_cord/train/inputs/audio10.wav\n",
      "data_3d_cord/train/labels/pose10.csv\n",
      "data_3d_cord/train/inputs/audio11.wav\n",
      "data_3d_cord/train/labels/pose11.csv\n",
      "data_3d_cord/train/inputs/audio12.wav\n",
      "data_3d_cord/train/labels/pose12.csv\n",
      "data_3d_cord/train/inputs/audio13.wav\n",
      "data_3d_cord/train/labels/pose13.csv\n",
      "data_3d_cord/train/inputs/audio14.wav\n",
      "data_3d_cord/train/labels/pose14.csv\n",
      "data_3d_cord/train/inputs/audio15.wav\n",
      "data_3d_cord/train/labels/pose15.csv\n",
      "data_3d_cord/train/inputs/audio16.wav\n",
      "data_3d_cord/train/labels/pose16.csv\n",
      "data_3d_cord/train/inputs/audio17.wav\n",
      "data_3d_cord/train/labels/pose17.csv\n",
      "data_3d_cord/train/inputs/audio18.wav\n",
      "data_3d_cord/train/labels/pose18.csv\n",
      "data_3d_cord/train/inputs/audio19.wav\n",
      "data_3d_cord/train/labels/pose19.csv\n",
      "data_3d_cord/train/inputs/audio20.wav\n",
      "data_3d_cord/train/labels/pose20.csv\n",
      "data_3d_cord/train/inputs/audio21.wav\n",
      "data_3d_cord/train/labels/pose21.csv\n",
      "data_3d_cord/train/inputs/audio22.wav\n",
      "data_3d_cord/train/labels/pose22.csv\n",
      "data_3d_cord/train/inputs/audio23.wav\n",
      "data_3d_cord/train/labels/pose23.csv\n",
      "data_3d_cord/train/inputs/audio24.wav\n",
      "data_3d_cord/train/labels/pose24.csv\n",
      "data_3d_cord/train/inputs/audio25.wav\n",
      "data_3d_cord/train/labels/pose25.csv\n",
      "data_3d_cord/train/inputs/audio26.wav\n",
      "data_3d_cord/train/labels/pose26.csv\n",
      "data_3d_cord/train/inputs/audio27.wav\n",
      "data_3d_cord/train/labels/pose27.csv\n",
      "data_3d_cord/train/inputs/audio28.wav\n",
      "data_3d_cord/train/labels/pose28.csv\n",
      "data_3d_cord/train/inputs/audio29.wav\n",
      "data_3d_cord/train/labels/pose29.csv\n",
      "data_3d_cord/train/inputs/audio30.wav\n",
      "data_3d_cord/train/labels/pose30.csv\n",
      "data_3d_cord/train/inputs/audio31.wav\n",
      "data_3d_cord/train/labels/pose31.csv\n",
      "data_3d_cord/train/inputs/audio32.wav\n",
      "data_3d_cord/train/labels/pose32.csv\n",
      "data_3d_cord/train/inputs/audio33.wav\n",
      "data_3d_cord/train/labels/pose33.csv\n",
      "data_3d_cord/train/inputs/audio34.wav\n",
      "data_3d_cord/train/labels/pose34.csv\n",
      "data_3d_cord/train/inputs/audio35.wav\n",
      "data_3d_cord/train/labels/pose35.csv\n",
      "data_3d_cord/train/inputs/audio36.wav\n",
      "data_3d_cord/train/labels/pose36.csv\n",
      "data_3d_cord/train/inputs/audio37.wav\n",
      "data_3d_cord/train/labels/pose37.csv\n",
      "data_3d_cord/train/inputs/audio38.wav\n",
      "data_3d_cord/train/labels/pose38.csv\n",
      "data_3d_cord/train/inputs/audio39.wav\n",
      "data_3d_cord/train/labels/pose39.csv\n",
      "data_3d_cord/train/inputs/audio40.wav\n",
      "data_3d_cord/train/labels/pose40.csv\n",
      "data_3d_cord/train/inputs/audio41.wav\n",
      "data_3d_cord/train/labels/pose41.csv\n",
      "data_3d_cord/test/inputs/audio42.wav\n",
      "data_3d_cord/test/labels/pose42.csv\n",
      "data_3d_cord/test/inputs/audio44.wav\n",
      "data_3d_cord/test/labels/pose44.csv\n",
      "data_3d_cord/dev/inputs/audio43.wav\n",
      "data_3d_cord/dev/labels/pose43.csv\n",
      "data_3d_cord/dev/inputs/audio45.wav\n",
      "data_3d_cord/dev/labels/pose45.csv\n"
     ]
    }
   ],
   "source": [
    "_split_and_format_data('data_3d_cord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "retired-samba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H:\\\\miniconda\\\\envs\\\\tensorflow\\\\lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
       " '-f',\n",
       " 'C:\\\\Users\\\\Wenwen\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-807be899-92c1-4b94-91f5-1b8f8b2d826f.json']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.argv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-stage",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
